{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "eNuQJPXDnOU2"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd  #data analysis\n",
        "import numpy as np  #numerical operations and arrays\n",
        "import re  #regular expressions for text cleaning\n",
        "from nltk.corpus import stopwords  #stop words for preprocessing\n",
        "from nltk.tokenize import word_tokenize  #tokenize text into words\n",
        "from nltk.stem import WordNetLemmatizer  #lemmatizes words to base form\n",
        "from sklearn.feature_extraction.text import CountVectorizer  #bag of words representation\n",
        "from sklearn.model_selection import train_test_split  #splits data into training and testing sets\n",
        "from sklearn.naive_bayes import MultinomialNB  #naive bayes for classification\n",
        "from sklearn.linear_model import LogisticRegression  #logistic regression for classification\n",
        "from sklearn.metrics import classification_report  #model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub  #tool for downloading datasets directly from kaggle"
      ],
      "metadata": {
        "id": "AQdchCYlpRAy"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"suchintikasarkar/sentiment-analysis-for-mental-health\")\n",
        "print(\"Path to dataset files:\", path)  #local path of the downloaded dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQTA5cnTpR5Z",
        "outputId": "7f06ed3c-328c-4e2a-80c4-466fabcf049e"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/suchintikasarkar/sentiment-analysis-for-mental-health/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(path))  #lists files in the dataset folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQtWrG87ubjE",
        "outputId": "1d4db7da-146c-45eb-fead-bfaa32c1c528"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Combined Data.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset from the downloaded path\n",
        "dataset_path = f\"{path}/Combined Data.csv\"  #constructs the full path to the dataset csv file\n",
        "df = pd.read_csv(dataset_path)  #read csv file into pandas dataframe\n",
        "print(\"Dataset columns:\", df.columns)  #prints column names to verify dataset structure (for debug)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PfZck_3pT3v",
        "outputId": "7e97216d-9d84-4b4d-fd3b-ab4c1ab92247"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns: Index(['Unnamed: 0', 'statement', 'status'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check unique classes in the original dataset\n",
        "unique_classes = df['status'].unique()\n",
        "print(\"Unique classes in the dataset:\", unique_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKVJI3fb1SdJ",
        "outputId": "eb521439-8512-47a1-ed0a-8e1ef495c541"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes in the dataset: ['Anxiety' 'Normal' 'Depression' 'Suicidal' 'Stress' 'Bipolar'\n",
            " 'Personality disorder']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply preprocessing and mapping\n",
        "df['statement'] = df['statement'].fillna('').astype(str)  #replace missing values\n",
        "print(\"Dataset loaded and preprocessed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOW_8FMf2KFE",
        "outputId": "8bba4b20-31fb-42a6-8685-1d227df2c915"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  #remove punctuation and special characters\n",
        "    text = text.lower()  #convert to lowercase\n",
        "    tokens = word_tokenize(text)  #tokenize text\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  #remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  #lemmatize tokens\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "Bi9j1_xKpV7W"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map multi-class labels to binary labels (normal, abnormal)\n",
        "def map_to_binary(label):\n",
        "    abnormal_labels = ['Anxiety', 'Bipolar', 'Depression', 'Personality disorder', 'Stress', 'Suicidal']\n",
        "    return 'abnormal' if label in abnormal_labels else 'normal'"
      ],
      "metadata": {
        "id": "q06tw5tI1Z3W"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply binary mapping\n",
        "df['binary_status'] = df['status'].apply(map_to_binary)"
      ],
      "metadata": {
        "id": "PI7lWr_t2YMA"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess text data\n",
        "df['cleaned_text'] = df['statement'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "I3g4fB162Zno"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of words representation\n",
        "vectorizer = CountVectorizer() #convert text to a bag of words representation\n",
        "X = vectorizer.fit_transform(df['cleaned_text']) #fit and transform the cleaned text to vectors\n",
        "y = df['binary_status']"
      ],
      "metadata": {
        "id": "RnIWw974pXNt"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure binary labels only\n",
        "y = y.apply(lambda x: 'normal' if x == 'normal' else 'abnormal')"
      ],
      "metadata": {
        "id": "ZjiFK-qa_OqH"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YJk3Bn7ipYet"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train naive bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_model = MultinomialNB()  #initialize naive bayes model\n",
        "nb_model.fit(X_train, y_train)  #train the model\n",
        "nb_predictions = nb_model.predict(X_test)  #predict on test data\n",
        "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, nb_predictions))  #evaluate performance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72p7Jfh1pZjW",
        "outputId": "b675ba33-d71f-4692-b363-89e093b07d7b"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.82      0.97      0.89      7282\n",
            "      normal       0.90      0.55      0.68      3327\n",
            "\n",
            "    accuracy                           0.84     10609\n",
            "   macro avg       0.86      0.76      0.79     10609\n",
            "weighted avg       0.85      0.84      0.83     10609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000)  #initialize logistic regression model (1000 max iterations)\n",
        "lr_model.fit(X_train, y_train)  #train the model\n",
        "lr_predictions = lr_model.predict(X_test)  #predict on test data\n",
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, lr_predictions))  #evaluate performance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slW4rYrBpanE",
        "outputId": "cc676389-6dcb-40c0-b179-b7b5df7a8b79"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    abnormal       0.97      0.94      0.96      7282\n",
            "      normal       0.88      0.94      0.91      3327\n",
            "\n",
            "    accuracy                           0.94     10609\n",
            "   macro avg       0.93      0.94      0.93     10609\n",
            "weighted avg       0.94      0.94      0.94     10609\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Test Accuracy (Naive Bayes):\", accuracy_score(y_test, nb_predictions))  # calculate accuracy for NB\n",
        "print(\"Test Accuracy (Logistic Regression):\", accuracy_score(y_test, lr_predictions))  #accuracy for LR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ7GmgANqNmo",
        "outputId": "6aa886ab-2e27-4418-ff98-89b37ecd28ca"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy (Naive Bayes): 0.838062022810821\n",
            "Test Accuracy (Logistic Regression): 0.9405221981336601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict new data\n",
        "new_posts = [\n",
        "    \"Had a great day with friends!\",\n",
        "    \"I feel so stressed and anxious lately.\",\n",
        "    \"I'm nervous about the future\",\n",
        "    \"What is the point of living anymore\"\n",
        "]\n",
        "new_posts_cleaned = [preprocess_text(post) for post in new_posts] #clean new posts\n",
        "new_posts_vectorized = vectorizer.transform(new_posts_cleaned) #transform posts to vectors\n",
        "new_predictions = lr_model.predict(new_posts_vectorized)\n",
        "print(\"Predictions for new posts:\", new_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI2oQu-Jpb0Y",
        "outputId": "888da282-961c-4616-fd68-9e2286596018"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new posts: ['normal' 'abnormal' 'abnormal' 'abnormal']\n"
          ]
        }
      ]
    }
  ]
}